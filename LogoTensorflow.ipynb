{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:60% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:60% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from PIL import Image as image\n",
    "from collections import defaultdict\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "ops = {'go': 0, 'turn_left': 1, 'turn_right': 2}\n",
    "cells = {'empty': 0, 'visited': 1}\n",
    "\n",
    "def visited_surrounding(bitmap, x, y):\n",
    "    num_visited = 0\n",
    "    for delx in [-1, 0, 1]:\n",
    "        for dely in [-1, 0, 1]:\n",
    "            if bitmap[-(y+dely)][x+delx] == cells['visited']:\n",
    "                num_visited += 1\n",
    "    return num_visited\n",
    "\n",
    "def try_generate_program(program_length, p_turn):\n",
    "    bitmap = defaultdict(lambda: defaultdict(lambda: cells['empty']))\n",
    "    program = []\n",
    "    x = y = phi = 0\n",
    "    bitmap[-y][x] = cells['visited']\n",
    "    for i in xrange(program_length):\n",
    "        if random.random() >= p_turn:\n",
    "            op = ops['go']\n",
    "            x += round(math.cos(phi))\n",
    "            y += round(math.sin(phi))\n",
    "            if bitmap[-y][x] != cells['empty']:\n",
    "                return None\n",
    "            else:\n",
    "                bitmap[-y][x] = cells['visited']\n",
    "            if visited_surrounding(bitmap, x, y) > 3:\n",
    "                return None\n",
    "        else:\n",
    "            if random.random() < 0.5:\n",
    "                op = ops['turn_left']\n",
    "                phi += math.pi/2\n",
    "                if len(program) > 0 and program[-1] == ops['turn_right']:\n",
    "                    return None\n",
    "            else:\n",
    "                op = ops['turn_right']\n",
    "                phi -= math.pi/2\n",
    "                if len(program) > 0 and program[-1] == ops['turn_left']:\n",
    "                    return None\n",
    "        program.append(op)\n",
    "    return program, bitmap\n",
    "\n",
    "def generate_program(program_length, p_turn):\n",
    "    for _ in xrange(1000):\n",
    "        r = try_generate_program(program_length, p_turn)\n",
    "        if r is not None:\n",
    "            return r\n",
    "\n",
    "def generate_programs(num_programs=1000, program_length=24, p_turn=0.3):\n",
    "    lookup = set()\n",
    "    width = height = program_length*2+1\n",
    "    programs = np.zeros((num_programs, program_length, 3))\n",
    "    bitmaps = np.zeros((num_programs, width * height))\n",
    "    i = 0\n",
    "    while i < num_programs:\n",
    "        program, bitmap = generate_program(program_length, p_turn)\n",
    "        program = tuple(program)\n",
    "        if tuple(program) not in lookup:\n",
    "            lookup.add(tuple(program))\n",
    "            for k in xrange(program_length):\n",
    "                programs[i, k, program[k]] = 1 # one-hot\n",
    "            ai = 0\n",
    "            for w in xrange(-program_length, program_length):\n",
    "                for h in xrange(-program_length, program_length):\n",
    "                    bitmaps[i, ai] = bitmap[w][h]\n",
    "                    ai += 1    \n",
    "            i += 1\n",
    "            print(i, end='   \\r')\n",
    "    return programs, bitmaps\n",
    "\n",
    "def to_program(program):\n",
    "    inv_ops = {v: k for k, v in ops.iteritems()}\n",
    "    rp = []\n",
    "    for i in xrange(len(program)):\n",
    "        for k in xrange(len(program[i])):\n",
    "            if program[i][k] == 1:\n",
    "                rp.append(inv_ops[k])\n",
    "    return rp\n",
    "\n",
    "def show_bitmap(bitmap, program_length):\n",
    "    width = height = program_length*2+1\n",
    "    data = np.zeros((width, height))\n",
    "    ia = 0\n",
    "    for w in xrange(-program_length, program_length):\n",
    "        for h in xrange(-program_length, program_length):\n",
    "            data[w+program_length, h+program_length] = bitmap[ia]\n",
    "            ia += 1\n",
    "    plt.axis('off')\n",
    "    plt.imshow(data, cmap=plt.cm.gray, aspect='equal')\n",
    "    \n",
    "def get_training_batch(programs, bitmaps, batch_programs, batch_bitmaps, batch_size, p_training):\n",
    "    batch_programs.fill(0)\n",
    "    batch_bitmaps.fill(0)\n",
    "    for i in xrange(batch_size):\n",
    "        r = int(random.random() * len(programs) * p_training)\n",
    "        batch_programs[i] = programs[r]\n",
    "        batch_bitmaps[i] = bitmaps[r]\n",
    "\n",
    "def get_test_batch(programs, bitmaps, test_programs, test_bitmaps, test_size, p_training):\n",
    "    test_programs.fill(0)\n",
    "    test_bitmaps.fill(0)\n",
    "    offset = int(p_training * len(programs))\n",
    "    for i in xrange(test_size):\n",
    "        test_programs[i] = programs[offset+i]\n",
    "        test_bitmaps[i] = bitmaps[offset+i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go', 'turn_right', 'go', 'turn_left', 'go', 'turn_right', 'go', 'go', 'go', 'go', 'go', 'go', 'turn_right', 'go', 'go', 'go']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAz5JREFUeJzt20Fqw1AMQMH+4vtfWT1AqUkLrgJvZpuEaPMQWMmZmQ+g\n53N7AGCH+CFK/BAlfogSP0SJH6LED1HihyjxQ9T1n192zvFzQnjYzJxX3mfzQ5T4IUr8ECV+iBI/\nRIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1Hihyjx\nQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogS\nP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco\n8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6I\nEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKH\nKPFD1LU9AO9nZn79mXPOA5PwJJsfosQPUeKHKPFDlPghytN+vvnpyf3dFeDuNZeA92TzQ5T4IUr8\nECV+iBI/RIkfopz6eNndye4vfwZil80PUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK\n/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+i\nru0B2DEz2yOwzOaHKPFDlPghSvwQJX6IEj9EOfVFnXO2R2CZzQ9R4oco8UOU+CFK/BAlfogSP0SJ\nH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU\n+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9E\niR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1Hih6gzM9szAAtsfogSP0SJH6LED1HihyjxQ5T4\nIUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CHqC1ziGv0AnS2F\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b7865b410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "program_length=16\n",
    "num_programs=1*1000\n",
    "programs, bitmaps = generate_programs(num_programs, program_length, p_turn=0.3)\n",
    "print(to_program(programs[0]))\n",
    "show_bitmap(bitmaps[0], program_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09241431  0.04535684  0.0470571   0.24307013 -0.12756351 -0.11550715\n",
      "  0.28640246 -0.15375225 -0.13265088  0.38347337 -0.19360229 -0.18987121\n",
      "  0.38519049 -0.19266117 -0.19253001  0.42073902 -0.23272651 -0.18801153\n",
      "  0.42285046 -0.21470191 -0.20814875  0.40835086 -0.2152489  -0.19310181\n",
      "  0.43474439 -0.21465695 -0.22008687  0.4161123  -0.19352558 -0.22258602\n",
      "  0.4388842  -0.21811834 -0.22076477  0.39456907 -0.19517522 -0.19939367\n",
      "  0.39978239 -0.21552373 -0.18425848  0.39627376 -0.19740278 -0.19887199\n",
      "  0.38278812 -0.19669154 -0.18609641  0.35725912 -0.17978504 -0.17747438\n",
      "  0.40071449 -0.18656458 -0.21415013  0.36325878 -0.18129012 -0.18196882\n",
      "  0.34057429 -0.17317824 -0.16739714  0.33806407 -0.15571056 -0.18235296\n",
      "  0.35332581 -0.21370396 -0.13962251  0.3322247  -0.1562347  -0.17598909\n",
      "  0.31816316 -0.15749218 -0.16067149  0.2805447  -0.11835641 -0.16218784]\n"
     ]
    }
   ],
   "source": [
    "width = height = program_length*2+1\n",
    "x = tf.placeholder(tf.float32, [None, width*height])\n",
    "# x is the input image as a long row vector\n",
    "W = tf.Variable(tf.zeros([width*height, program_length * len(ops.keys())]))\n",
    "# W are the weights, going from each input to output, where each output op is one-hot encoded\n",
    "b = tf.Variable(tf.zeros([program_length * len(ops.keys())]))\n",
    "# b are the biases for each output\n",
    "#y = tf.nn.softmax(tf.reshape(tf.matmul(x, W) + b, [-1, program_length, len(ops.keys())]), dim=2)\n",
    "y = tf.reshape(tf.matmul(x, W) + b, [-1, program_length, len(ops.keys())])\n",
    "# y are the predicted program for each x, one-hot encoded, so it's shape is num_programs x program_length x num_ops\n",
    "y_ = tf.placeholder(tf.float32, [None, program_length, len(ops.keys())])\n",
    "# y_ is the correct one-hot encoded program, for computing cross-entropy\n",
    "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1])) # loss function is cross_entropy\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "num_training_runs = 10*1000\n",
    "batch_size = 100\n",
    "p_training = 0.9\n",
    "width = height = program_length*2+1\n",
    "batch_programs = np.zeros((batch_size, program_length, 3))\n",
    "batch_bitmaps = np.zeros((batch_size, width * height))\n",
    "for i in range(num_training_runs):\n",
    "    get_training_batch(programs, bitmaps, batch_programs, batch_bitmaps, batch_size, p_training)\n",
    "    _, train_error, weights, bias = sess.run([train_step, cross_entropy, W, b], feed_dict={x: batch_bitmaps, y_: batch_programs})\n",
    "    print((i, train_error), end='   \\r')\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "#print(weights)\n",
    "print(bias)\n",
    "\n",
    "#correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "#accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "test_size = int(len(programs) * (1.0 - p_training))\n",
    "test_programs = np.zeros((test_size, program_length, 3))\n",
    "test_bitmaps = np.zeros((test_size, width * height))\n",
    "get_test_batch(programs, bitmaps, test_programs, test_bitmaps, test_size, p_training)\n",
    "\n",
    "#print(sess.run(accuracy, feed_dict={x: test_bitmaps, y_: test_programs}))\n",
    "\n",
    "actuals = sess.run(y_, feed_dict={x: test_bitmaps, y_: test_programs})\n",
    "prediction_probas = sess.run(y, feed_dict={x: test_bitmaps, y_: test_programs})\n",
    "\n",
    "predictions = np.zeros((len(prediction_probas), program_length, 3))\n",
    "for i in xrange(len(prediction_probas)):\n",
    "    for j in xrange(program_length):\n",
    "        max_proba = 0\n",
    "        which = 0\n",
    "        for k in xrange(len(ops.keys())):\n",
    "            if prediction_probas[i][j][k] > max_proba:\n",
    "                which = k\n",
    "                max_proba = prediction_probas[i][j][k]\n",
    "        predictions[i][j][which] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'turn_right', 'go', 'go', 'go', 'go', 'turn_left', 'go', 'turn_left', 'turn_right', 'turn_right', 'turn_left', 'go', 'go', 'turn_left']\n",
      "['go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go']\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]]\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "index = 568\n",
    "print(to_program(actuals[index]))\n",
    "print(to_program(predictions[index]))\n",
    "print(actuals[index])\n",
    "print(predictions[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965382048715\n",
      "0.725392058725\n"
     ]
    }
   ],
   "source": [
    "def num_go(li, program_length):\n",
    "    num_go = 0\n",
    "    for i in xrange(len(li)):\n",
    "        for j in xrange(program_length):\n",
    "            if li[i][j][0] == 1: num_go += 1\n",
    "    return num_go\n",
    "num_predictions_go = num_go(predictions, program_length)\n",
    "num_actuals_go = num_go(actuals, program_length)\n",
    "print(float(num_predictions_go) / (len(predictions) * program_length))\n",
    "print(float(num_actuals_go) / (len(actuals) * program_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9002, 0.58700305)                                                                 \r"
     ]
    }
   ],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "W_conv = weight_variable([3, 3, 1, program_length * len(ops.keys())])\n",
    "x_image = tf.reshape(x, [-1, width, height, 1])\n",
    "h_conv = tf.nn.relu(conv2d(x_image, W_conv))\n",
    "h_pool = max_pool_2x2(h_conv)\n",
    "reduced_width = int(math.ceil(float(width)/2))\n",
    "reduced_height = int(math.ceil(float(height)/2))\n",
    "h_pool_reshaped = tf.reshape(h_pool, [-1, reduced_width * reduced_height * program_length * len(ops.keys())])\n",
    "W = weight_variable([reduced_width * reduced_height * program_length * len(ops.keys()), program_length * len(ops.keys())])\n",
    "b = bias_variable([program_length * len(ops.keys())])\n",
    "h = tf.nn.relu(tf.matmul(h_pool_reshaped, W) + b)\n",
    "y = tf.reshape(h, [-1, program_length, len(ops.keys())])\n",
    "y_ = tf.placeholder(tf.float32, [None, program_length, len(ops.keys())])\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "num_training_runs = 10*1000\n",
    "batch_size = 100\n",
    "p_training = 0.9\n",
    "width = height = program_length*2+1\n",
    "batch_programs = np.zeros((batch_size, program_length, 3))\n",
    "batch_bitmaps = np.zeros((batch_size, width * height))\n",
    "for i in range(num_training_runs):\n",
    "    get_training_batch(programs, bitmaps, batch_programs, batch_bitmaps, batch_size, p_training)\n",
    "    _, train_error = sess.run([train_step, cross_entropy], feed_dict={x: batch_bitmaps, y_: batch_programs})\n",
    "    print((i, train_error), end='   \\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actuals = sess.run(y_, feed_dict={x: test_bitmaps, y_: test_programs})\n",
    "prediction_probas = sess.run(y, feed_dict={x: test_bitmaps, y_: test_programs})\n",
    "\n",
    "predictions = np.zeros((len(prediction_probas), program_length, 3))\n",
    "for i in xrange(len(prediction_probas)):\n",
    "    for j in xrange(program_length):\n",
    "        max_proba = 0\n",
    "        which = 0\n",
    "        for k in xrange(len(ops.keys())):\n",
    "            if prediction_probas[i][j][k] > max_proba:\n",
    "                which = k\n",
    "                max_proba = prediction_probas[i][j][k]\n",
    "        predictions[i][j][which] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go', 'go', 'turn_right', 'turn_right', 'turn_left', 'turn_left', 'go', 'go', 'turn_left', 'go']\n",
      "['go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go', 'go']\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]]\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "index = 49\n",
    "print(to_program(actuals[index]))\n",
    "print(to_program(predictions[index]))\n",
    "print(actuals[index])\n",
    "print(predictions[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAzBJREFUeJzt3UFqw0AQAMFM8P+/PHmAHYgP1kZ01VEINJdmYCXQ7O4X\n0PN9egDgDPFDlPghSvwQJX6IEj9EiR+ixA9R4oeox5UPmxmfE8KH7e785T6bH6LED1HihyjxQ5T4\nIUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJ\nH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU\n+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9E\niR+ixA9R4oco8UOU+CFK/BAlfogSP0Q9Tg8AV9jdl9dn5uJJ/g+bH6LED1HihyjxQ5T4IUr8ECV+\niBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6L8sYdb\n+e3PO7zP5oco8UOU+CFK/BAlfogSP0R51ceTu75Om5nTI9yKzQ9R4oco8UOU+CFK/BDltJ8nTs0b\nbH6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQP\nUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8\nECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LE\nD1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK\n/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+i\nxA9R4oco8UOU+CFK/BAlfoia3T09A3CAzQ9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4\nIUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9E/QAtHRT7CdAtmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fba1cc40f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_bitmap(bitmaps[6], program_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n",
      "Step 0 Loss 2.36417\n",
      "Step 1 Loss 68.0244\n",
      "Step 2 Loss 107.754\n",
      "Step 3 Loss 108.806\n",
      "Step 4 Loss 120.415\n",
      "Step 5 Loss 91.2408\n",
      "Step 6 Loss 82.8679\n",
      "Step 7 Loss 74.0711\n",
      "Step 8 Loss 67.9222\n",
      "Step 9 Loss 65.5863\n",
      "Step 10 Loss 41.7279\n",
      "Step 11 Loss 70.4665\n",
      "Step 12 Loss 37.9402\n",
      "Step 13 Loss 70.103\n",
      "Step 14 Loss 28.7639\n",
      "Step 15 Loss 53.8991\n",
      "Step 16 Loss 33.4404\n",
      "Step 17 Loss 55.5575\n",
      "Step 18 Loss 28.296\n",
      "Step 19 Loss 51.9772\n",
      "Step 20 Loss 24.7965\n",
      "Step 21 Loss 51.1222\n",
      "Step 22 Loss 20.8621\n",
      "Step 23 Loss 66.1234\n",
      "Step 24 Loss 20.1714\n",
      "Step 25 Loss 78.5796\n",
      "Step 26 Loss 13.5079\n",
      "Step 27 Loss 51.576\n",
      "Step 28 Loss 14.7861\n",
      "Step 29 Loss 50.6275\n",
      "Step 30 Loss 10.3732\n",
      "Step 31 Loss 49.1898\n",
      "Step 32 Loss 30.9288\n",
      "Step 33 Loss 46.1534\n",
      "Step 34 Loss 25.6362\n",
      "Step 35 Loss 38.1543\n",
      "Step 36 Loss 26.6174\n",
      "Step 37 Loss 34.3045\n",
      "Step 38 Loss 21.0567\n",
      "Step 39 Loss 30.7294\n",
      "Step 40 Loss 23.864\n",
      "Step 41 Loss 29.4516\n",
      "Step 42 Loss 23.4147\n",
      "Step 43 Loss 27.1624\n",
      "Step 44 Loss 23.5547\n",
      "Step 45 Loss 26.8663\n",
      "Step 46 Loss 22.0636\n",
      "Step 47 Loss 26.2402\n",
      "Step 48 Loss 22.0201\n",
      "Step 49 Loss 23.9532\n",
      "Step 50 Loss 23.9154\n",
      "Step 51 Loss 21.0232\n",
      "Step 52 Loss 27.1679\n",
      "Step 53 Loss 20.6733\n",
      "Step 54 Loss 29.1225\n",
      "Step 55 Loss 19.3581\n",
      "Step 56 Loss 29.4901\n",
      "Step 57 Loss 18.7432\n",
      "Step 58 Loss 30.2334\n",
      "Step 59 Loss 17.9106\n",
      "Step 60 Loss 29.4339\n",
      "Step 61 Loss 15.6665\n",
      "Step 62 Loss 27.8939\n",
      "Step 63 Loss 15.7607\n",
      "Step 64 Loss 29.4238\n",
      "Step 65 Loss 12.2103\n",
      "Step 66 Loss 29.9558\n",
      "Step 67 Loss 13.9816\n",
      "Step 68 Loss 28.6964\n",
      "Step 69 Loss 13.9966\n",
      "Step 70 Loss 28.2594\n",
      "Step 71 Loss 12.2337\n",
      "Step 72 Loss 27.7841\n",
      "Step 73 Loss 11.2048\n",
      "Step 74 Loss 26.5332\n",
      "Step 75 Loss 20.7891\n",
      "Step 76 Loss 32.3221\n",
      "Step 77 Loss 20.1184\n",
      "Step 78 Loss 27.375\n",
      "Step 79 Loss 20.5508\n",
      "Step 80 Loss 24.0631\n",
      "Step 81 Loss 20.3886\n",
      "Step 82 Loss 21.1432\n",
      "Step 83 Loss 21.3767\n",
      "Step 84 Loss 20.8798\n",
      "Step 85 Loss 19.8947\n",
      "Step 86 Loss 17.9135\n",
      "Step 87 Loss 21.3712\n",
      "Step 88 Loss 16.1206\n",
      "Step 89 Loss 21.6749\n",
      "Step 90 Loss 13.9931\n",
      "Step 91 Loss 23.2072\n",
      "Step 92 Loss 12.2485\n",
      "Step 93 Loss 21.4909\n",
      "Step 94 Loss 13.705\n",
      "Step 95 Loss 19.506\n",
      "Step 96 Loss 11.2498\n",
      "Step 97 Loss 20.4633\n",
      "Step 98 Loss 11.3407\n",
      "Step 99 Loss 20.5298\n",
      "New data, epoch 1\n",
      "Step 0 Loss 12.5271\n",
      "Step 1 Loss 16.114\n",
      "Step 2 Loss 15.2239\n",
      "Step 3 Loss 15.4636\n",
      "Step 4 Loss 12.4767\n",
      "Step 5 Loss 17.2506\n",
      "Step 6 Loss 13.6943\n",
      "Step 7 Loss 16.0691\n",
      "Step 8 Loss 12.7849\n",
      "Step 9 Loss 15.3716\n",
      "Step 10 Loss 13.7488\n",
      "Step 11 Loss 14.4258\n",
      "Step 12 Loss 10.967\n",
      "Step 13 Loss 15.3414\n",
      "Step 14 Loss 12.0751\n",
      "Step 15 Loss 15.6248\n",
      "Step 16 Loss 11.1077\n",
      "Step 17 Loss 15.995\n",
      "Step 18 Loss 9.94587\n",
      "Step 19 Loss 16.1745\n",
      "Step 20 Loss 9.67832\n",
      "Step 21 Loss 16.3101\n",
      "Step 22 Loss 8.4995\n",
      "Step 23 Loss 17.0424\n",
      "Step 24 Loss 7.77128\n",
      "Step 25 Loss 16.4671\n",
      "Step 26 Loss 6.87916\n",
      "Step 27 Loss 15.3871\n",
      "Step 28 Loss 7.27251\n",
      "Step 29 Loss 15.8104\n",
      "Step 30 Loss 8.21938\n",
      "Step 31 Loss 17.061\n",
      "Step 32 Loss 17.281\n",
      "Step 33 Loss 22.7248\n",
      "Step 34 Loss 17.8872\n",
      "Step 35 Loss 23.8779\n",
      "Step 36 Loss 14.7014\n",
      "Step 37 Loss 24.4685\n",
      "Step 38 Loss 16.1777\n",
      "Step 39 Loss 23.2561\n",
      "Step 40 Loss 14.4166\n",
      "Step 41 Loss 21.0259\n",
      "Step 42 Loss 13.4009\n",
      "Step 43 Loss 22.6808\n",
      "Step 44 Loss 11.7567\n",
      "Step 45 Loss 21.9906\n",
      "Step 46 Loss 12.0033\n",
      "Step 47 Loss 20.3593\n",
      "Step 48 Loss 11.6902\n",
      "Step 49 Loss 16.6835\n",
      "Step 50 Loss 16.0533\n",
      "Step 51 Loss 14.0651\n",
      "Step 52 Loss 17.5283\n",
      "Step 53 Loss 14.3341\n",
      "Step 54 Loss 16.912\n",
      "Step 55 Loss 13.4135\n",
      "Step 56 Loss 16.1428\n",
      "Step 57 Loss 13.6741\n",
      "Step 58 Loss 15.5935\n",
      "Step 59 Loss 14.4238\n",
      "Step 60 Loss 15.9697\n",
      "Step 61 Loss 13.3919\n",
      "Step 62 Loss 16.3787\n",
      "Step 63 Loss 13.0353\n",
      "Step 64 Loss 13.6359\n",
      "Step 65 Loss 13.79\n",
      "Step 66 Loss 12.1713\n",
      "Step 67 Loss 14.4213\n",
      "Step 68 Loss 12.9341\n",
      "Step 69 Loss 13.6264\n",
      "Step 70 Loss 12.3048\n",
      "Step 71 Loss 13.2799\n",
      "Step 72 Loss 13.5194\n",
      "Step 73 Loss 12.2145\n",
      "Step 74 Loss 13.8908\n",
      "Step 75 Loss 9.91075\n",
      "Step 76 Loss 15.229\n",
      "Step 77 Loss 10.6034\n",
      "Step 78 Loss 15.3114\n",
      "Step 79 Loss 10.7594\n",
      "Step 80 Loss 14.0425\n",
      "Step 81 Loss 11.401\n",
      "Step 82 Loss 13.66\n",
      "Step 83 Loss 10.2643\n",
      "Step 84 Loss 12.7095\n",
      "Step 85 Loss 11.5168\n",
      "Step 86 Loss 13.5352\n",
      "Step 87 Loss 9.86268\n",
      "Step 88 Loss 13.2139\n",
      "Step 89 Loss 10.8421\n",
      "Step 90 Loss 12.3094\n",
      "Step 91 Loss 10.6216\n",
      "Step 92 Loss 11.313\n",
      "Step 93 Loss 11.1071\n",
      "Step 94 Loss 11.1049\n",
      "Step 95 Loss 12.3016\n",
      "Step 96 Loss 9.82558\n",
      "Step 97 Loss 11.3704\n",
      "Step 98 Loss 10.0818\n",
      "Step 99 Loss 12.0425\n",
      "New data, epoch 2\n",
      "Step 0 Loss 10.3384\n",
      "Step 1 Loss 10.1738\n",
      "Step 2 Loss 13.3104\n",
      "Step 3 Loss 9.74983\n",
      "Step 4 Loss 12.322\n",
      "Step 5 Loss 10.5364\n",
      "Step 6 Loss 12.3901\n",
      "Step 7 Loss 10.3115\n",
      "Step 8 Loss 10.7819\n",
      "Step 9 Loss 10.4392\n",
      "Step 10 Loss 9.80024\n",
      "Step 11 Loss 11.7208\n",
      "Step 12 Loss 8.30068\n",
      "Step 13 Loss 11.1426\n",
      "Step 14 Loss 9.73214\n",
      "Step 15 Loss 9.85686\n",
      "Step 16 Loss 9.59244\n",
      "Step 17 Loss 11.3425\n",
      "Step 18 Loss 8.68188\n",
      "Step 19 Loss 11.0351\n",
      "Step 20 Loss 8.13113\n",
      "Step 21 Loss 10.8273\n",
      "Step 22 Loss 7.96362\n",
      "Step 23 Loss 11.7006\n",
      "Step 24 Loss 7.596\n",
      "Step 25 Loss 11.0164\n",
      "Step 26 Loss 6.78067\n",
      "Step 27 Loss 11.121\n",
      "Step 28 Loss 8.01452\n",
      "Step 29 Loss 9.95211\n",
      "Step 30 Loss 7.78594\n",
      "Step 31 Loss 10.3302\n",
      "Step 32 Loss 7.01348\n",
      "Step 33 Loss 10.9121\n",
      "Step 34 Loss 5.22132\n",
      "Step 35 Loss 12.3125\n",
      "Step 36 Loss 5.49529\n",
      "Step 37 Loss 11.9488\n",
      "Step 38 Loss 5.74781\n",
      "Step 39 Loss 11.6621\n",
      "Step 40 Loss 5.87197\n",
      "Step 41 Loss 11.6591\n",
      "Step 42 Loss 4.71899\n",
      "Step 43 Loss 10.886\n",
      "Step 44 Loss 4.17949\n",
      "Step 45 Loss 11.7658\n",
      "Step 46 Loss 4.89547\n",
      "Step 47 Loss 10.737\n",
      "Step 48 Loss 5.57717\n",
      "Step 49 Loss 11.3436\n",
      "Step 50 Loss 4.80143\n",
      "Step 51 Loss 11.4813\n",
      "Step 52 Loss 3.43108\n",
      "Step 53 Loss 12.3533\n",
      "Step 54 Loss 3.57086\n",
      "Step 55 Loss 12.6358\n",
      "Step 56 Loss 3.8177\n",
      "Step 57 Loss 11.805\n",
      "Step 58 Loss 3.51809\n",
      "Step 59 Loss 11.1112\n",
      "Step 60 Loss 4.38997\n",
      "Step 61 Loss 11.2831\n",
      "Step 62 Loss 3.58457\n",
      "Step 63 Loss 11.0971\n",
      "Step 64 Loss 4.21887\n",
      "Step 65 Loss 10.5577\n",
      "Step 66 Loss 3.98751\n",
      "Step 67 Loss 11.0731\n",
      "Step 68 Loss 4.14353\n",
      "Step 69 Loss 10.2726\n",
      "Step 70 Loss 2.71841\n",
      "Step 71 Loss 9.85393\n",
      "Step 72 Loss 4.70931\n",
      "Step 73 Loss 10.0977\n",
      "Step 74 Loss 4.08425\n",
      "Step 75 Loss 9.38938\n",
      "Step 76 Loss 4.84322\n",
      "Step 77 Loss 9.06852\n",
      "Step 78 Loss 4.65703\n",
      "Step 79 Loss 9.45164\n",
      "Step 80 Loss 4.67719\n",
      "Step 81 Loss 9.28678\n",
      "Step 82 Loss 4.35851\n",
      "Step 83 Loss 9.05852\n",
      "Step 84 Loss 4.55669\n",
      "Step 85 Loss 8.79691\n",
      "Step 86 Loss 3.93554\n",
      "Step 87 Loss 9.17401\n",
      "Step 88 Loss 3.47857\n",
      "Step 89 Loss 10.0773\n",
      "Step 90 Loss 3.26786\n",
      "Step 91 Loss 9.71749\n",
      "Step 92 Loss 3.13548\n",
      "Step 93 Loss 9.89953\n",
      "Step 94 Loss 3.50235\n",
      "Step 95 Loss 8.99691\n",
      "Step 96 Loss 3.40585\n",
      "Step 97 Loss 9.489\n",
      "Step 98 Loss 3.03975\n",
      "Step 99 Loss 9.84724\n",
      "New data, epoch 3\n",
      "Step 0 Loss 5.701\n",
      "Step 1 Loss 4.49992\n",
      "Step 2 Loss 7.09761\n",
      "Step 3 Loss 7.22328\n",
      "Step 4 Loss 12.6409\n",
      "Step 5 Loss 7.50104\n",
      "Step 6 Loss 12.0501\n",
      "Step 7 Loss 7.3089\n",
      "Step 8 Loss 10.9018\n",
      "Step 9 Loss 8.11345\n",
      "Step 10 Loss 9.50374\n",
      "Step 11 Loss 8.72123\n",
      "Step 12 Loss 10.3305\n",
      "Step 13 Loss 8.02877\n",
      "Step 14 Loss 9.09321\n",
      "Step 15 Loss 7.00594\n",
      "Step 16 Loss 10.6627\n",
      "Step 17 Loss 6.8918\n",
      "Step 18 Loss 10.8999\n",
      "Step 19 Loss 7.23973\n",
      "Step 20 Loss 10.3695\n",
      "Step 21 Loss 8.26489\n",
      "Step 22 Loss 9.68721\n",
      "Step 23 Loss 8.67766\n",
      "Step 24 Loss 9.68939\n",
      "Step 25 Loss 8.13144\n",
      "Step 26 Loss 10.0972\n",
      "Step 27 Loss 7.50966\n",
      "Step 28 Loss 10.2332\n",
      "Step 29 Loss 8.27716\n",
      "Step 30 Loss 9.64142\n",
      "Step 31 Loss 7.75766\n",
      "Step 32 Loss 9.12776\n",
      "Step 33 Loss 8.48019\n",
      "Step 34 Loss 9.27751\n",
      "Step 35 Loss 7.91268\n",
      "Step 36 Loss 8.1109\n",
      "Step 37 Loss 7.12128\n",
      "Step 38 Loss 10.2171\n",
      "Step 39 Loss 7.77376\n",
      "Step 40 Loss 9.27523\n",
      "Step 41 Loss 7.60064\n",
      "Step 42 Loss 9.2119\n",
      "Step 43 Loss 8.71629\n",
      "Step 44 Loss 8.2746\n",
      "Step 45 Loss 9.39534\n",
      "Step 46 Loss 7.17053\n",
      "Step 47 Loss 9.43926\n",
      "Step 48 Loss 7.23696\n",
      "Step 49 Loss 8.99466\n",
      "Step 50 Loss 7.17488\n",
      "Step 51 Loss 9.87616\n",
      "Step 52 Loss 7.05823\n",
      "Step 53 Loss 8.88435\n",
      "Step 54 Loss 7.16609\n",
      "Step 55 Loss 9.30611\n",
      "Step 56 Loss 7.19647\n",
      "Step 57 Loss 9.55072\n",
      "Step 58 Loss 6.47437\n",
      "Step 59 Loss 7.73431\n",
      "Step 60 Loss 8.4211\n",
      "Step 61 Loss 8.02009\n",
      "Step 62 Loss 7.17144\n",
      "Step 63 Loss 8.74557\n",
      "Step 64 Loss 7.86456\n",
      "Step 65 Loss 8.34989\n",
      "Step 66 Loss 7.47797\n",
      "Step 67 Loss 7.78591\n",
      "Step 68 Loss 8.08338\n",
      "Step 69 Loss 6.92423\n",
      "Step 70 Loss 8.37199\n",
      "Step 71 Loss 6.78625\n",
      "Step 72 Loss 7.3479\n",
      "Step 73 Loss 7.94343\n",
      "Step 74 Loss 11.5314\n",
      "Step 75 Loss 8.33681\n",
      "Step 76 Loss 11.3049\n",
      "Step 77 Loss 8.99355\n",
      "Step 78 Loss 10.3373\n",
      "Step 79 Loss 8.8146\n",
      "Step 80 Loss 10.653\n",
      "Step 81 Loss 9.25891\n",
      "Step 82 Loss 9.67145\n",
      "Step 83 Loss 9.5276\n",
      "Step 84 Loss 8.43412\n",
      "Step 85 Loss 8.65537\n",
      "Step 86 Loss 9.51448\n",
      "Step 87 Loss 8.99746\n",
      "Step 88 Loss 8.93504\n",
      "Step 89 Loss 9.1881\n",
      "Step 90 Loss 8.57281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 91 Loss 8.99711\n",
      "Step 92 Loss 8.21081\n",
      "Step 93 Loss 8.88872\n",
      "Step 94 Loss 7.8309\n",
      "Step 95 Loss 9.52736\n",
      "Step 96 Loss 7.11444\n",
      "Step 97 Loss 9.92685\n",
      "Step 98 Loss 6.78097\n",
      "Step 99 Loss 9.97854\n",
      "New data, epoch 4\n",
      "Step 0 Loss 6.82723\n",
      "Step 1 Loss 5.93025\n",
      "Step 2 Loss 10.3924\n",
      "Step 3 Loss 6.03026\n",
      "Step 4 Loss 9.69959\n",
      "Step 5 Loss 6.53202\n",
      "Step 6 Loss 8.95468\n",
      "Step 7 Loss 7.11688\n",
      "Step 8 Loss 8.4544\n",
      "Step 9 Loss 7.75568\n",
      "Step 10 Loss 7.8908\n",
      "Step 11 Loss 7.69545\n",
      "Step 12 Loss 7.71419\n",
      "Step 13 Loss 7.41969\n",
      "Step 14 Loss 7.25687\n",
      "Step 15 Loss 6.72291\n",
      "Step 16 Loss 7.40439\n",
      "Step 17 Loss 7.30888\n",
      "Step 18 Loss 7.96057\n",
      "Step 19 Loss 7.4266\n",
      "Step 20 Loss 7.12069\n",
      "Step 21 Loss 7.69002\n",
      "Step 22 Loss 7.00618\n",
      "Step 23 Loss 8.15585\n",
      "Step 24 Loss 5.60336\n",
      "Step 25 Loss 8.21483\n",
      "Step 26 Loss 5.39885\n",
      "Step 27 Loss 9.01659\n",
      "Step 28 Loss 4.85018\n",
      "Step 29 Loss 8.56607\n",
      "Step 30 Loss 4.6373\n",
      "Step 31 Loss 10.1302\n",
      "Step 32 Loss 3.94889\n",
      "Step 33 Loss 9.88899\n",
      "Step 34 Loss 4.05849\n",
      "Step 35 Loss 9.05186\n",
      "Step 36 Loss 4.07571\n",
      "Step 37 Loss 9.58021\n",
      "Step 38 Loss 3.93744\n",
      "Step 39 Loss 9.65004\n",
      "Step 40 Loss 3.51232\n",
      "Step 41 Loss 9.88689\n",
      "Step 42 Loss 3.00166\n",
      "Step 43 Loss 9.62427\n",
      "Step 44 Loss 3.82913\n",
      "Step 45 Loss 9.18988\n",
      "Step 46 Loss 3.83325\n",
      "Step 47 Loss 6.42966\n",
      "Step 48 Loss 6.55171\n",
      "Step 49 Loss 7.09973\n",
      "Step 50 Loss 5.41944\n",
      "Step 51 Loss 7.13333\n",
      "Step 52 Loss 5.94015\n",
      "Step 53 Loss 7.01331\n",
      "Step 54 Loss 5.82481\n",
      "Step 55 Loss 6.91706\n",
      "Step 56 Loss 4.48205\n",
      "Step 57 Loss 7.57962\n",
      "Step 58 Loss 4.62717\n",
      "Step 59 Loss 8.16855\n",
      "Step 60 Loss 3.85863\n",
      "Step 61 Loss 8.24822\n",
      "Step 62 Loss 4.55421\n",
      "Step 63 Loss 7.74763\n",
      "Step 64 Loss 4.35468\n",
      "Step 65 Loss 6.67528\n",
      "Step 66 Loss 5.20238\n",
      "Step 67 Loss 6.29079\n",
      "Step 68 Loss 4.77833\n",
      "Step 69 Loss 6.83088\n",
      "Step 70 Loss 4.82536\n",
      "Step 71 Loss 7.25167\n",
      "Step 72 Loss 4.48307\n",
      "Step 73 Loss 6.82573\n",
      "Step 74 Loss 3.91309\n",
      "Step 75 Loss 6.875\n",
      "Step 76 Loss 4.51208\n",
      "Step 77 Loss 7.2855\n",
      "Step 78 Loss 3.67571\n",
      "Step 79 Loss 7.59639\n",
      "Step 80 Loss 3.47393\n",
      "Step 81 Loss 7.27281\n",
      "Step 82 Loss 3.88976\n",
      "Step 83 Loss 6.94585\n",
      "Step 84 Loss 4.32034\n",
      "Step 85 Loss 6.79708\n",
      "Step 86 Loss 3.25227\n",
      "Step 87 Loss 6.43585\n",
      "Step 88 Loss 4.13562\n",
      "Step 89 Loss 6.48675\n",
      "Step 90 Loss 3.66398\n",
      "Step 91 Loss 6.6929\n",
      "Step 92 Loss 3.18295\n",
      "Step 93 Loss 6.85148\n",
      "Step 94 Loss 3.53735\n",
      "Step 95 Loss 6.75077\n",
      "Step 96 Loss 3.7558\n",
      "Step 97 Loss 7.21104\n",
      "Step 98 Loss 3.41212\n",
      "Step 99 Loss 6.45613\n",
      "New data, epoch 5\n",
      "Step 0 Loss 4.82216\n",
      "Step 1 Loss 2.78946\n",
      "Step 2 Loss 4.95157\n",
      "Step 3 Loss 7.38606\n",
      "Step 4 Loss 3.59757\n",
      "Step 5 Loss 8.55182\n",
      "Step 6 Loss 3.69754\n",
      "Step 7 Loss 8.15245\n",
      "Step 8 Loss 3.514\n",
      "Step 9 Loss 8.07829\n",
      "Step 10 Loss 2.72622\n",
      "Step 11 Loss 7.88643\n",
      "Step 12 Loss 4.04198\n",
      "Step 13 Loss 8.39505\n",
      "Step 14 Loss 3.56119\n",
      "Step 15 Loss 7.71603\n",
      "Step 16 Loss 3.44411\n",
      "Step 17 Loss 7.50103\n",
      "Step 18 Loss 3.8052\n",
      "Step 19 Loss 7.91957\n",
      "Step 20 Loss 3.1843\n",
      "Step 21 Loss 8.02651\n",
      "Step 22 Loss 3.58036\n",
      "Step 23 Loss 7.81277\n",
      "Step 24 Loss 3.99\n",
      "Step 25 Loss 7.53916\n",
      "Step 26 Loss 3.97931\n",
      "Step 27 Loss 7.81765\n",
      "Step 28 Loss 4.01112\n",
      "Step 29 Loss 6.49167\n",
      "Step 30 Loss 4.81409\n",
      "Step 31 Loss 6.37384\n",
      "Step 32 Loss 4.44689\n",
      "Step 33 Loss 6.84509\n",
      "Step 34 Loss 4.06101\n",
      "Step 35 Loss 5.89056\n",
      "Step 36 Loss 4.33867\n",
      "Step 37 Loss 6.66919\n",
      "Step 38 Loss 4.21002\n",
      "Step 39 Loss 6.96145\n",
      "Step 40 Loss 4.51311\n",
      "Step 41 Loss 6.5556\n",
      "Step 42 Loss 4.04225\n",
      "Step 43 Loss 6.98616\n",
      "Step 44 Loss 4.57482\n",
      "Step 45 Loss 6.5319\n",
      "Step 46 Loss 4.51924\n",
      "Step 47 Loss 6.40945\n",
      "Step 48 Loss 3.97294\n",
      "Step 49 Loss 6.64372\n",
      "Step 50 Loss 4.04088\n",
      "Step 51 Loss 6.98099\n",
      "Step 52 Loss 3.87453\n",
      "Step 53 Loss 6.56318\n",
      "Step 54 Loss 4.13828\n",
      "Step 55 Loss 6.78119\n",
      "Step 56 Loss 3.90452\n",
      "Step 57 Loss 6.04851\n",
      "Step 58 Loss 4.22302\n",
      "Step 59 Loss 6.38972\n",
      "Step 60 Loss 4.50536\n",
      "Step 61 Loss 6.64967\n",
      "Step 62 Loss 3.56763\n",
      "Step 63 Loss 6.83558\n",
      "Step 64 Loss 3.53769\n",
      "Step 65 Loss 6.9597\n",
      "Step 66 Loss 3.2242\n",
      "Step 67 Loss 6.69458\n",
      "Step 68 Loss 3.52976\n",
      "Step 69 Loss 6.87604\n",
      "Step 70 Loss 2.87379\n",
      "Step 71 Loss 6.29148\n",
      "Step 72 Loss 3.87783\n",
      "Step 73 Loss 6.03158\n",
      "Step 74 Loss 4.55595\n",
      "Step 75 Loss 5.96719\n",
      "Step 76 Loss 4.24244\n",
      "Step 77 Loss 6.66073\n",
      "Step 78 Loss 4.08523\n",
      "Step 79 Loss 6.19806\n",
      "Step 80 Loss 4.5992\n",
      "Step 81 Loss 5.78823\n",
      "Step 82 Loss 4.72866\n",
      "Step 83 Loss 6.03986\n",
      "Step 84 Loss 4.34538\n",
      "Step 85 Loss 6.00532\n",
      "Step 86 Loss 4.23711\n",
      "Step 87 Loss 5.34342\n",
      "Step 88 Loss 4.20776\n",
      "Step 89 Loss 5.8288\n",
      "Step 90 Loss 4.14724\n",
      "Step 91 Loss 5.80384\n",
      "Step 92 Loss 4.14413\n",
      "Step 93 Loss 5.83012\n",
      "Step 94 Loss 4.83045\n",
      "Step 95 Loss 5.88144\n",
      "Step 96 Loss 4.54858\n",
      "Step 97 Loss 5.70712\n",
      "Step 98 Loss 4.2865\n",
      "Step 99 Loss 6.35178\n",
      "New data, epoch 6\n",
      "Step 0 Loss 4.71565\n",
      "Step 1 Loss 2.97033\n",
      "Step 2 Loss 3.73914\n",
      "Step 3 Loss 4.93179\n",
      "Step 4 Loss 10.0509\n",
      "Step 5 Loss 6.8188\n",
      "Step 6 Loss 8.80284\n",
      "Step 7 Loss 7.86947\n",
      "Step 8 Loss 8.97375\n",
      "Step 9 Loss 6.76563\n",
      "Step 10 Loss 8.63936\n",
      "Step 11 Loss 7.74455\n",
      "Step 12 Loss 8.15486\n",
      "Step 13 Loss 8.76402\n",
      "Step 14 Loss 6.55898\n",
      "Step 15 Loss 9.17831\n",
      "Step 16 Loss 6.63984\n",
      "Step 17 Loss 8.29899\n",
      "Step 18 Loss 6.77415\n",
      "Step 19 Loss 8.54461\n",
      "Step 20 Loss 7.02746\n",
      "Step 21 Loss 8.42652\n",
      "Step 22 Loss 6.96359\n",
      "Step 23 Loss 8.31677\n",
      "Step 24 Loss 6.56014\n",
      "Step 25 Loss 8.78183\n",
      "Step 26 Loss 6.26762\n",
      "Step 27 Loss 7.80332\n",
      "Step 28 Loss 6.18681\n",
      "Step 29 Loss 7.97553\n",
      "Step 30 Loss 6.12759\n",
      "Step 31 Loss 7.24959\n",
      "Step 32 Loss 6.04875\n",
      "Step 33 Loss 7.37789\n",
      "Step 34 Loss 7.13188\n",
      "Step 35 Loss 7.54978\n",
      "Step 36 Loss 6.31953\n",
      "Step 37 Loss 7.74669\n",
      "Step 38 Loss 6.24067\n",
      "Step 39 Loss 6.78736\n",
      "Step 40 Loss 6.82388\n",
      "Step 41 Loss 7.36648\n",
      "Step 42 Loss 6.2191\n",
      "Step 43 Loss 7.46245\n",
      "Step 44 Loss 5.54433\n",
      "Step 45 Loss 7.2205\n",
      "Step 46 Loss 6.16453\n",
      "Step 47 Loss 6.22278\n",
      "Step 48 Loss 5.50677\n",
      "Step 49 Loss 6.97303\n",
      "Step 50 Loss 6.56899\n",
      "Step 51 Loss 6.39893\n",
      "Step 52 Loss 6.42783\n",
      "Step 53 Loss 6.8695\n",
      "Step 54 Loss 6.43611\n",
      "Step 55 Loss 6.45013\n",
      "Step 56 Loss 6.00418\n",
      "Step 57 Loss 6.81594\n",
      "Step 58 Loss 5.6023\n",
      "Step 59 Loss 6.45923\n",
      "Step 60 Loss 5.26067\n",
      "Step 61 Loss 5.09499\n",
      "Step 62 Loss 5.78284\n",
      "Step 63 Loss 5.91742\n",
      "Step 64 Loss 6.35388\n",
      "Step 65 Loss 5.03585\n",
      "Step 66 Loss 5.18658\n",
      "Step 67 Loss 5.17145\n",
      "Step 68 Loss 6.08546\n",
      "Step 69 Loss 5.79887\n",
      "Step 70 Loss 6.00936\n",
      "Step 71 Loss 5.87179\n",
      "Step 72 Loss 5.56429\n",
      "Step 73 Loss 6.0561\n",
      "Step 74 Loss 5.41983\n",
      "Step 75 Loss 5.56905\n",
      "Step 76 Loss 4.77529\n",
      "Step 77 Loss 4.17392\n",
      "Step 78 Loss 5.5544\n",
      "Step 79 Loss 7.28485\n",
      "Step 80 Loss 6.00081\n",
      "Step 81 Loss 7.04693\n",
      "Step 82 Loss 5.95582\n",
      "Step 83 Loss 7.07992\n",
      "Step 84 Loss 5.73642\n",
      "Step 85 Loss 7.08146\n",
      "Step 86 Loss 4.71582\n",
      "Step 87 Loss 7.77372\n",
      "Step 88 Loss 4.45737\n",
      "Step 89 Loss 7.49876\n",
      "Step 90 Loss 4.86907\n",
      "Step 91 Loss 7.13209\n",
      "Step 92 Loss 5.04102\n",
      "Step 93 Loss 7.3981\n",
      "Step 94 Loss 5.4505\n",
      "Step 95 Loss 6.95563\n",
      "Step 96 Loss 5.38914\n",
      "Step 97 Loss 6.66646\n",
      "Step 98 Loss 4.38799\n",
      "Step 99 Loss 7.34186\n",
      "New data, epoch 7\n",
      "Step 0 Loss 4.65323\n",
      "Step 1 Loss 4.15256\n",
      "Step 2 Loss 5.41927\n",
      "Step 3 Loss 7.29523\n",
      "Step 4 Loss 7.32188\n",
      "Step 5 Loss 7.60489\n",
      "Step 6 Loss 6.75833\n",
      "Step 7 Loss 8.09009\n",
      "Step 8 Loss 6.2739\n",
      "Step 9 Loss 7.5938\n",
      "Step 10 Loss 6.03829\n",
      "Step 11 Loss 7.53423\n",
      "Step 12 Loss 6.40297\n",
      "Step 13 Loss 7.11761\n",
      "Step 14 Loss 6.33301\n",
      "Step 15 Loss 6.95571\n",
      "Step 16 Loss 7.36565\n",
      "Step 17 Loss 7.32771\n",
      "Step 18 Loss 6.23281\n",
      "Step 19 Loss 7.47304\n",
      "Step 20 Loss 6.23104\n",
      "Step 21 Loss 7.15858\n",
      "Step 22 Loss 5.12629\n",
      "Step 23 Loss 7.9285\n",
      "Step 24 Loss 4.98625\n",
      "Step 25 Loss 7.55146\n",
      "Step 26 Loss 5.23993\n",
      "Step 27 Loss 7.66254\n",
      "Step 28 Loss 5.06464\n",
      "Step 29 Loss 6.85307\n",
      "Step 30 Loss 6.09392\n",
      "Step 31 Loss 6.73132\n",
      "Step 32 Loss 5.9799\n",
      "Step 33 Loss 7.04751\n",
      "Step 34 Loss 6.14544\n",
      "Step 35 Loss 6.10906\n",
      "Step 36 Loss 6.20494\n",
      "Step 37 Loss 6.02407\n",
      "Step 38 Loss 5.69085\n",
      "Step 39 Loss 6.2058\n",
      "Step 40 Loss 5.82806\n",
      "Step 41 Loss 6.24785\n",
      "Step 42 Loss 5.01587\n",
      "Step 43 Loss 6.59244\n",
      "Step 44 Loss 5.98965\n",
      "Step 45 Loss 5.59827\n",
      "Step 46 Loss 5.05614\n",
      "Step 47 Loss 5.08156\n",
      "Step 48 Loss 6.05302\n",
      "Step 49 Loss 6.22924\n",
      "Step 50 Loss 5.03235\n",
      "Step 51 Loss 6.59469\n",
      "Step 52 Loss 5.15539\n",
      "Step 53 Loss 6.59842\n",
      "Step 54 Loss 4.57638\n",
      "Step 55 Loss 6.58636\n",
      "Step 56 Loss 4.63785\n",
      "Step 57 Loss 6.45741\n",
      "Step 58 Loss 4.58908\n",
      "Step 59 Loss 6.40985\n",
      "Step 60 Loss 4.68274\n",
      "Step 61 Loss 5.70713\n",
      "Step 62 Loss 5.55823\n",
      "Step 63 Loss 6.35054\n",
      "Step 64 Loss 5.37415\n",
      "Step 65 Loss 5.77976\n",
      "Step 66 Loss 5.70607\n",
      "Step 67 Loss 5.43506\n",
      "Step 68 Loss 5.14211\n",
      "Step 69 Loss 5.25812\n",
      "Step 70 Loss 5.18441\n",
      "Step 71 Loss 5.25484\n",
      "Step 72 Loss 4.40429\n",
      "Step 73 Loss 4.37062\n",
      "Step 74 Loss 4.15706\n",
      "Step 75 Loss 2.84116\n",
      "Step 76 Loss 3.66426\n",
      "Step 77 Loss 2.60815\n",
      "Step 78 Loss 3.78134\n",
      "Step 79 Loss 2.40032\n",
      "Step 80 Loss 3.57549\n",
      "Step 81 Loss 3.17665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 82 Loss 3.73403\n",
      "Step 83 Loss 2.66325\n",
      "Step 84 Loss 3.35176\n",
      "Step 85 Loss 3.12094\n",
      "Step 86 Loss 3.40521\n",
      "Step 87 Loss 2.6562\n",
      "Step 88 Loss 3.76412\n",
      "Step 89 Loss 2.88325\n",
      "Step 90 Loss 2.92286\n",
      "Step 91 Loss 3.0799\n",
      "Step 92 Loss 3.08934\n",
      "Step 93 Loss 3.26037\n",
      "Step 94 Loss 3.09054\n",
      "Step 95 Loss 3.15735\n",
      "Step 96 Loss 3.22266\n",
      "Step 97 Loss 3.08807\n",
      "Step 98 Loss 3.31393\n",
      "Step 99 Loss 2.98092\n",
      "New data, epoch 8\n",
      "Step 0 Loss 4.23591\n",
      "Step 1 Loss 1.92254\n",
      "Step 2 Loss 1.70893\n",
      "Step 3 Loss 1.61197\n",
      "Step 4 Loss 1.73949\n",
      "Step 5 Loss 1.63957\n",
      "Step 6 Loss 1.69951\n",
      "Step 7 Loss 1.66552\n",
      "Step 8 Loss 1.66058\n",
      "Step 9 Loss 1.735\n",
      "Step 10 Loss 1.76033\n",
      "Step 11 Loss 1.61241\n",
      "Step 12 Loss 1.71116\n",
      "Step 13 Loss 1.70205\n",
      "Step 14 Loss 1.81303\n",
      "Step 15 Loss 1.68399\n",
      "Step 16 Loss 1.71657\n",
      "Step 17 Loss 1.80757\n",
      "Step 18 Loss 1.67288\n",
      "Step 19 Loss 1.65134\n",
      "Step 20 Loss 1.5153\n",
      "Step 21 Loss 1.72925\n",
      "Step 22 Loss 1.8355\n",
      "Step 23 Loss 1.64846\n",
      "Step 24 Loss 1.72844\n",
      "Step 25 Loss 1.68411\n",
      "Step 26 Loss 1.80094\n",
      "Step 27 Loss 1.64231\n",
      "Step 28 Loss 1.75458\n",
      "Step 29 Loss 1.76441\n",
      "Step 30 Loss 1.77203\n",
      "Step 31 Loss 1.66424\n",
      "Step 32 Loss 1.62226\n",
      "Step 33 Loss 1.7071\n",
      "Step 34 Loss 1.6866\n",
      "Step 35 Loss 1.72207\n",
      "Step 36 Loss 1.77242\n",
      "Step 37 Loss 1.72599\n",
      "Step 38 Loss 1.752\n",
      "Step 39 Loss 1.7619\n",
      "Step 40 Loss 1.70222\n",
      "Step 41 Loss 1.62144\n",
      "Step 42 Loss 1.73054\n",
      "Step 43 Loss 1.66782\n",
      "Step 44 Loss 1.57716\n",
      "Step 45 Loss 1.72933\n",
      "Step 46 Loss 1.69905\n",
      "Step 47 Loss 1.72208\n",
      "Step 48 Loss 1.68693\n",
      "Step 49 Loss 1.7108\n",
      "Step 50 Loss 1.81239\n",
      "Step 51 Loss 1.66451\n",
      "Step 52 Loss 1.80683\n",
      "Step 53 Loss 1.75769\n",
      "Step 54 Loss 1.71707\n",
      "Step 55 Loss 1.64508\n",
      "Step 56 Loss 1.60677\n",
      "Step 57 Loss 1.65731\n",
      "Step 58 Loss 1.63104\n",
      "Step 59 Loss 1.59041\n",
      "Step 60 Loss 1.69756\n",
      "Step 61 Loss 1.78805\n",
      "Step 62 Loss 1.62498\n",
      "Step 63 Loss 1.56454\n",
      "Step 64 Loss 1.82008\n",
      "Step 65 Loss 1.64935\n",
      "Step 66 Loss 1.5519\n",
      "Step 67 Loss 1.70443\n",
      "Step 68 Loss 1.78431\n",
      "Step 69 Loss 1.70652\n",
      "Step 70 Loss 1.62889\n",
      "Step 71 Loss 1.58914\n",
      "Step 72 Loss 1.69295\n",
      "Step 73 Loss 1.78514\n",
      "Step 74 Loss 1.67404\n",
      "Step 75 Loss 1.6413\n",
      "Step 76 Loss 1.62817\n",
      "Step 77 Loss 1.79036\n",
      "Step 78 Loss 1.63625\n",
      "Step 79 Loss 1.76729\n",
      "Step 80 Loss 1.67076\n",
      "Step 81 Loss 1.63154\n",
      "Step 82 Loss 1.72422\n",
      "Step 83 Loss 1.61972\n",
      "Step 84 Loss 1.67265\n",
      "Step 85 Loss 1.68903\n",
      "Step 86 Loss 1.71836\n",
      "Step 87 Loss 1.76073\n",
      "Step 88 Loss 1.63398\n",
      "Step 89 Loss 1.59644\n",
      "Step 90 Loss 1.66128\n",
      "Step 91 Loss 1.7024\n",
      "Step 92 Loss 1.57927\n",
      "Step 93 Loss 1.64505\n",
      "Step 94 Loss 1.69907\n",
      "Step 95 Loss 1.64129\n",
      "Step 96 Loss 1.56346\n",
      "Step 97 Loss 1.67699\n",
      "Step 98 Loss 1.73012\n",
      "Step 99 Loss 1.73484\n",
      "New data, epoch 9\n",
      "Step 0 Loss 2.57487\n",
      "Step 1 Loss 1.48286\n",
      "Step 2 Loss 1.678\n",
      "Step 3 Loss 1.74917\n",
      "Step 4 Loss 1.64839\n",
      "Step 5 Loss 1.64531\n",
      "Step 6 Loss 1.59235\n",
      "Step 7 Loss 1.62217\n",
      "Step 8 Loss 1.72827\n",
      "Step 9 Loss 1.69347\n",
      "Step 10 Loss 1.57369\n",
      "Step 11 Loss 1.59632\n",
      "Step 12 Loss 1.62206\n",
      "Step 13 Loss 1.65956\n",
      "Step 14 Loss 1.62902\n",
      "Step 15 Loss 1.67851\n",
      "Step 16 Loss 1.65074\n",
      "Step 17 Loss 1.65111\n",
      "Step 18 Loss 1.59628\n",
      "Step 19 Loss 1.61054\n",
      "Step 20 Loss 1.58346\n",
      "Step 21 Loss 1.76471\n",
      "Step 22 Loss 1.73361\n",
      "Step 23 Loss 1.64017\n",
      "Step 24 Loss 1.66881\n",
      "Step 25 Loss 1.63502\n",
      "Step 26 Loss 1.54603\n",
      "Step 27 Loss 1.77244\n",
      "Step 28 Loss 1.59333\n",
      "Step 29 Loss 1.60978\n",
      "Step 30 Loss 1.60086\n",
      "Step 31 Loss 1.71375\n",
      "Step 32 Loss 1.70018\n",
      "Step 33 Loss 1.65778\n",
      "Step 34 Loss 1.64887\n",
      "Step 35 Loss 1.67304\n",
      "Step 36 Loss 1.62412\n",
      "Step 37 Loss 1.62307\n",
      "Step 38 Loss 1.58705\n",
      "Step 39 Loss 1.67214\n",
      "Step 40 Loss 1.6652\n",
      "Step 41 Loss 1.64575\n",
      "Step 42 Loss 1.5685\n",
      "Step 43 Loss 1.64144\n",
      "Step 44 Loss 1.67981\n",
      "Step 45 Loss 1.66124\n",
      "Step 46 Loss 1.5816\n",
      "Step 47 Loss 1.65657\n",
      "Step 48 Loss 1.56046\n",
      "Step 49 Loss 1.67084\n",
      "Step 50 Loss 1.60416\n",
      "Step 51 Loss 1.63904\n",
      "Step 52 Loss 1.58095\n",
      "Step 53 Loss 1.51615\n",
      "Step 54 Loss 1.61314\n",
      "Step 55 Loss 1.50647\n",
      "Step 56 Loss 1.57368\n",
      "Step 57 Loss 1.62662\n",
      "Step 58 Loss 1.59962\n",
      "Step 59 Loss 1.66464\n",
      "Step 60 Loss 1.56575\n",
      "Step 61 Loss 1.6895\n",
      "Step 62 Loss 1.59016\n",
      "Step 63 Loss 1.56569\n",
      "Step 64 Loss 1.59812\n",
      "Step 65 Loss 1.65994\n",
      "Step 66 Loss 1.5694\n",
      "Step 67 Loss 1.48565\n",
      "Step 68 Loss 1.5986\n",
      "Step 69 Loss 1.60389\n",
      "Step 70 Loss 1.64387\n",
      "Step 71 Loss 1.50486\n",
      "Step 72 Loss 1.56811\n",
      "Step 73 Loss 1.60403\n",
      "Step 74 Loss 1.66136\n",
      "Step 75 Loss 1.65384\n",
      "Step 76 Loss 1.60546\n",
      "Step 77 Loss 1.57707\n",
      "Step 78 Loss 1.52048\n",
      "Step 79 Loss 1.57011\n",
      "Step 80 Loss 1.6843\n",
      "Step 81 Loss 1.55295\n",
      "Step 82 Loss 1.51468\n",
      "Step 83 Loss 1.55272\n",
      "Step 84 Loss 1.63374\n",
      "Step 85 Loss 1.53589\n",
      "Step 86 Loss 1.65969\n",
      "Step 87 Loss 1.52986\n",
      "Step 88 Loss 1.68291\n",
      "Step 89 Loss 1.66736\n",
      "Step 90 Loss 1.67308\n",
      "Step 91 Loss 1.55188\n",
      "Step 92 Loss 1.48223\n",
      "Step 93 Loss 1.70707\n",
      "Step 94 Loss 1.60634\n",
      "Step 95 Loss 1.56734\n",
      "Step 96 Loss 1.63111\n",
      "Step 97 Loss 1.55421\n",
      "Step 98 Loss 1.56995\n",
      "Step 99 Loss 1.5887\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f9e9a5c9e493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mget_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_programs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_bitmaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_programs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_bitmaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mrepeated_batch_bitmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_bitmaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogram_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mactuals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_probas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_series\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrepeated_batch_bitmaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_programs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_current_state\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_probas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogram_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_probas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtrencseni/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtrencseni/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "width = height = program_length*2+1\n",
    "batch_size = 100\n",
    "p_training = 0.9\n",
    "state_size = width * height * 4\n",
    "batch_programs = np.zeros((batch_size, program_length, 3))\n",
    "batch_bitmaps = np.zeros((batch_size, width * height))\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [None, width * height * program_length])\n",
    "y_ = tf.placeholder(tf.int32, [None, program_length, len(ops.keys())])\n",
    "init_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "labels_series = tf.unstack(y_, axis=1)\n",
    "inputs_series = tf.split(x, program_length, 1)\n",
    "cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "#cell = tf.contrib.rnn.LSTMCell(state_size)\n",
    "states_series, current_state = tf.contrib.rnn.static_rnn(cell, inputs_series, init_state)\n",
    "\n",
    "W = tf.Variable(np.random.rand(state_size, len(ops.keys())), dtype=tf.float32)\n",
    "b = tf.Variable(np.zeros((1, len(ops.keys()))), dtype=tf.float32)\n",
    "logits_series = [tf.matmul(state, W) + b for state in states_series]\n",
    "predictions_series = [tf.nn.softmax(logits) for logits in logits_series]\n",
    "losses = [tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels) for logits, labels in zip(logits_series, labels_series)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(0.1).minimize(total_loss)\n",
    "\n",
    "test_size = int(len(programs) * (1.0 - p_training))\n",
    "test_programs = np.zeros((test_size, program_length, 3))\n",
    "test_bitmaps = np.zeros((test_size, width * height))\n",
    "get_test_batch(programs, bitmaps, test_programs, test_bitmaps, test_size, p_training)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch_idx in range(10):\n",
    "        _current_state = np.zeros((batch_size, state_size))\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "        for batch_idx in range(100):\n",
    "            get_training_batch(programs, bitmaps, batch_programs, batch_bitmaps, batch_size, p_training)\n",
    "            repeated_batch_bitmaps = np.tile(batch_bitmaps, [1, program_length])\n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run([total_loss, train_step, current_state, predictions_series], feed_dict={x: repeated_batch_bitmaps, y_: batch_programs, init_state:_current_state})\n",
    "            print(\"Step\", batch_idx, \"Loss\", _total_loss)\n",
    "get_training_batch(test_programs, test_bitmaps, batch_programs, batch_bitmaps, batch_size, p_training=1.0)\n",
    "repeated_batch_bitmaps = np.tile(batch_bitmaps, [1, program_length])\n",
    "actuals, prediction_probas = sess.run([y_, predictions_series], feed_dict={x: repeated_batch_bitmaps, y_: batch_programs, init_state: _current_state})\n",
    "predictions = np.zeros((len(prediction_probas), program_length, 3))\n",
    "for i in xrange(len(prediction_probas)):\n",
    "    for j in xrange(program_length):\n",
    "        max_proba = 0\n",
    "        which = 0\n",
    "        for k in xrange(len(ops.keys())):\n",
    "            if prediction_probas[i][j][k] > max_proba:\n",
    "                which = k\n",
    "                max_proba = prediction_probas[i][j][k]\n",
    "        predictions[i][j][which] = 1\n",
    "for index in xrange(10):\n",
    "    print(to_program(actuals[index]))\n",
    "    print(to_program(predictions[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 16, 3)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_programs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=(?, 17424) dtype=float32>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17424"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width * height * program_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'split:0' shape=(?, 1089) dtype=float32>,\n",
       " <tf.Tensor 'split:1' shape=(?, 1089) dtype=float32>,\n",
       " <tf.Tensor 'split:2' shape=(?, 1089) dtype=float32>,\n",
       " <tf.Tensor 'split:3' shape=(?, 1089) dtype=float32>,\n",
       " <tf.Tensor 'split:4' shape=(?, 1089) dtype=float32>,\n",
       " <tf.Tensor 'split:5' shape=(?, 1089) dtype=float32>,\n",
       " <tf.Tensor 'split:6' shape=(?, 1089) dtype=float32>,\n",
       " <tf.Tensor 'split:7' shape=(?, 1089) dtype=float32>,\n",
       " <tf.Tensor 'split:8' shape=(?, 1089) dtype=float32>,\n",
       " <tf.Tensor 'split:9' shape=(?, 1089) dtype=float32>,\n",
       " <tf.Tensor 'split:10' shape=(?, 1089) dtype=float32>,\n",
       " <tf.Tensor 'split:11' shape=(?, 1089) dtype=float32>,\n",
       " <tf.Tensor 'split:12' shape=(?, 1089) dtype=float32>,\n",
       " <tf.Tensor 'split:13' shape=(?, 1089) dtype=float32>,\n",
       " <tf.Tensor 'split:14' shape=(?, 1089) dtype=float32>,\n",
       " <tf.Tensor 'split:15' shape=(?, 1089) dtype=float32>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'unstack:0' shape=(?, 3) dtype=int32>,\n",
       " <tf.Tensor 'unstack:1' shape=(?, 3) dtype=int32>,\n",
       " <tf.Tensor 'unstack:2' shape=(?, 3) dtype=int32>,\n",
       " <tf.Tensor 'unstack:3' shape=(?, 3) dtype=int32>,\n",
       " <tf.Tensor 'unstack:4' shape=(?, 3) dtype=int32>,\n",
       " <tf.Tensor 'unstack:5' shape=(?, 3) dtype=int32>,\n",
       " <tf.Tensor 'unstack:6' shape=(?, 3) dtype=int32>,\n",
       " <tf.Tensor 'unstack:7' shape=(?, 3) dtype=int32>,\n",
       " <tf.Tensor 'unstack:8' shape=(?, 3) dtype=int32>,\n",
       " <tf.Tensor 'unstack:9' shape=(?, 3) dtype=int32>,\n",
       " <tf.Tensor 'unstack:10' shape=(?, 3) dtype=int32>,\n",
       " <tf.Tensor 'unstack:11' shape=(?, 3) dtype=int32>,\n",
       " <tf.Tensor 'unstack:12' shape=(?, 3) dtype=int32>,\n",
       " <tf.Tensor 'unstack:13' shape=(?, 3) dtype=int32>,\n",
       " <tf.Tensor 'unstack:14' shape=(?, 3) dtype=int32>,\n",
       " <tf.Tensor 'unstack:15' shape=(?, 3) dtype=int32>]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
